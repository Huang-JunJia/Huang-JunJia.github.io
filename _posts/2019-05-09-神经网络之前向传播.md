---
layout:     post
title:      "神经网络之前向传播"
subtitle:   "在介绍前向传播之前，先介绍一下神经网络的实现过程，这样子能更好地理解前向传播的作用。"
date:       2019-05-09
author:     "木夏"
header-img: "img/post-bg-digital-native.jpg"
catalog: true
mathjax: true
tags:
    - 神经网络

---

>`I love you three thousand times.——《复仇联盟4：终局之战》`
><br/>`我想译为：“吻你万千”。`

## Begin
## 1.什么是前向传播？
在介绍前向传播之前，先介绍一下神经网络的实现过程，这样子能更好地理解前向传播的作用。

### 1.1神经网络实现过程
我们先来理解一下神经网络的实现过程：
 1. 准备数据集，提取特征，将特征数据作为输入喂入神经网络（Neural Network）；
 2. 搭建神经网络结构，先搭建计算图，再用会话运行。（**利用前向传播算法——>计算输出**）；
 3. 将大量特征数据喂入神经网络，优化神经网络的参数（即每条边的权重）（**利用反向传播算法，得到使得loss最小的参数，即最优**）；
 4. 固定好参数，使用训练好的模型预测分类。

### 1.2前向传播的过程
根据神经网络的实现过程可知，前向传播在神经网络中占据重要的作用。所以想要先向弄清楚神经网络，那么首先就要了解前向传播算法。**前向传播算法就是给定输入，然后计算每一个神经元的输出，再将该神经元的输出作为下一个神经元的输入，依序进行，最后计算出整个神经网络的输出值**。
### 1.3前向传播需要三部分信息
#### 1.3.1第一部分：神经网络的输入
输入就是从实体中提取出来的特征向量，比如零件的特征向量可以是长度、重量，人的特征向量可以是身高、体重。
#### 1.3.2第二部分：神经网络的连接结构
神经网络是由神经元组成的，神经网络的结构给出不同神经元之间的连接结构。比如全连接神经网络，就是相邻两层之间任意两个神经元之间都有连接。
#### 1.3.3第三部分：神经元的参数
如下图，神经元$ a_{11}$的参数有：$W_{1,1}^{(1)}$、$W_{2,1}^{(1)}$、$W_{1,1}^{(2)}$，其中$W_{1,1}^{(1)}$是第一层神经元的参数，表示连接$x_1$、$a_{11}$边上的权重；$W_{1,1}^{(2)}$是第二层神经元的参数，表示连接$a_{11}$、$Y$边上的权重。求解神经网络的过程，其实就是求解边上权重的过程。给定了神经网络的结构和边上的权重，就可以通过前向传播算法来计算这个神经网络的输出了。
![此处输入图片的描述][1]
## 2.前向传播过程实战
我们利用一个全连接神经网络，来解释一下前向传播算法的过程。
依旧是以下面这张图为例子：
![此处输入图片的描述][2]
### 2.1梳理一下前向传播
#### 2.1.1输入特征数据
输入的数据为两个特征，即体积和重量。体积：0.7，重量：0.5。
#### 2.1.2计算隐藏层节点
隐藏层有3个节点，分别是$a_{11}$、$a_{12}$、$a_{13}$。$a_{11}$的计算过程如下：$$ a_{11} =x_1*w_{1,1}^{(1)}+x_2*w_{2,1}^{(1)} = 0.7*0.2+0.5*0.3=0.29$$同理可得：$a_{12}=0.32$、$a_{13}=0.38$。
#### 2.1.3得到输出层
最后得到输出层$ y=-0.015$，这便是前向传播的过程。
### 2.2网络层推理构建

 1. 第一层：
![此处输入图片的描述][3]
 2. 第二层：
 ![此处输入图片的描述][4]

#### 2.2.1构建第一层：
 - 输入为体积和重量，所以输入为一个1行2列的矩阵$X$。如果输入一组数据则是1行2列，如果是N组数据则为N行2列的矩阵。此处暂定输入矩阵$X$为1行2列：$$X=[[0.7,0.5]]$$。
 - 第一层权重矩阵$W^{（1）}$的构建，因为$W^{（1）}$**前面有2个节点**，**后面有3个节点**，所以$W^{（1）}$矩阵为**2行3列**。
$$
   W^{(1)}= \begin{bmatrix}
    [w_{1,1}^{(1)} & w_{1,2}^{(1)} & w_{1,3}^{(1)} ]\\
    [w_{2,1}^{(1)}& w_{2,2}^{(1)}&w_{2,3}^{(1)}] \\
    \end{bmatrix}= \begin{bmatrix}
    [0.2 & 0.1 & 0.4 ]\\
    [0.3& 0.5&0.2] \\
    \end{bmatrix}
$$
 - 输出的$a$节点可以组成的矩阵$A$得到这样的表示：$$A =XW^{（1）}=\begin{bmatrix}
    [a_{11} & a_{12} & a_{13} ]\\
    \end{bmatrix}=\begin{bmatrix}
    [0.29 & 0.32 & 0.38 ]\\
    \end{bmatrix}$$因为$X$矩阵为**1行2列**，$W^{(1)}$矩阵为**2行3列**，所以得到的$a$节点的矩阵应该为**1行3列**。这里提醒一下，为什么是`[[`呢？因为`[[`表示的是矩阵，而一个`[`表示的是向量。
#### 2.2.2构建第二层：
 - 输入即为$A$矩阵：$$A =\begin{bmatrix}
    [a_{11} & a_{12} & a_{13} ]\\
    \end{bmatrix}=\begin{bmatrix}
    [0.29 & 0.32 & 0.38 ]\\
    \end{bmatrix}$$
 - 第二层权重矩阵$W^{（2）}$的构建，因为$W^{（2）}$**前面有3个节点，后面有一个节点**，所以$W^{（2）}$是**3行1列**：$$W^{(2)}= \begin{bmatrix}
    [w_{1,1}^{(2)} ]\\
    [w_{2,1}^{(2)}] \\
[w_{3,1}^{(2)}] \\
    \end{bmatrix} = \begin{bmatrix}
    [0.1 ]\\
    [0.1] \\
[-0.2] \\
    \end{bmatrix}$$
 - 输出$y$可以用矩阵相乘得到结果：$$ y=AW^{（2）}=0.29*0.1+0.32*0.1+0.38*(-0.2)=-0.015$$,因为矩阵$A$为**1行3列**，矩阵$W^{(2)}$为**3行1列**，所以最后得到的$y$为**1行1列**。
## 3.利用TensorFlow构建网络
根据2的网络层结构推理，我们一层一层地利用TensorFlow来构建网络。
### 3.1TensorFlow构建第一层网络
```python
#构建第一层网络
X = tf.placeholder(tf.float32,shape=(None,2))#定义输入的特征数据，为N行2列。如果喂入1组数据，可将shape=(1,2),这样就是1行2列。
W1 = tf.Variable([[0.2,0.1,0.4],[0.3,0.5,0.2]])#定义第一层权重矩阵W1，2行3列
A = tf.matmul(X,W1)#输出的a节点可以组成的矩阵A，A=X*W1
```
### 3.2TensorFlow构建第二层网络
```python
#构建第二层网络
W2 = tf.Variable([[0.1],[0.1],[-0.1]])#定义第二层权重矩阵W1，3行1列
y =tf.matmul(A,W2)#矩阵相乘，得到输出y
```
### 3.3用会话计算结果
会话计算每个节点前，记得要先初始化所有变量：
```python
init_op = tf.global_variables_initializer()
    sess.run(init_op)
```
会话计算结果：
```python
with tf.Session() as sess:
    init_op = tf.global_variables_initializer()#初始化所有变量
    sess.run(init_op)
    print(sess.run(y, feed_dict={X: [[0.7, 0.5]]}))#喂入的1组特征数据：[[0.7, 0.5]]，计算结果y
    print(  sess.run(y, feed_dict={X:[[0.7,0.5],[0.8,0.6],[0.7,0.4]]}) )#喂入的3组特征数据：[[0.7,0.5],[0.8,0.6],[0.7,0.4]]，计算结果y
```
 - 喂入的1组特征数据：`[[0.7, 0.5]]`，输出结果$y$:
\begin{bmatrix}
   [0.02300001]\\
\end{bmatrix}
 - 喂入的3组特征数据：`[[0.7,0.5],[0.8,0.6],[0.7,0.4]]`
输出结果$y$:\begin{bmatrix}
   [0.02300001]\\
   [0.02800001]\\
   [0.017     ]
    \end{bmatrix}
## End
一个全连接的神经网络前向传播算法就介绍完毕了，因为我们预先给定了各个边的权重$w$,所以这个前向传播实则就是数学运算，矩阵相乘，最后得到网络的输出结果。
而实际当中，我们是不知道各个边的权重$w$是多少的，所以我们就要利用手中的数据，通过**反向传播算法**来算出这个神经网络中各个边最优的权重$w$,那如何判定是最优呢？这就扯到损失函数了，下面我会讲到的。

## 参考文章
- 《TensorFlow实战Google深度学习框架》
- 《人工智能实践：TensorFlow笔记》

  [1]: https://s2.ax1x.com/2019/05/09/Eg0gmV.png
  [2]: https://s2.ax1x.com/2019/05/09/Eg0gmV.png
  [3]: https://s2.ax1x.com/2019/05/09/E2Fk4A.png
  [4]: https://s2.ax1x.com/2019/05/09/E2F8Cn.png
